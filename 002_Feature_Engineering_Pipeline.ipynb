{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Why this kernel\n",
    "\n",
    "The purpose of this kernel is to provide you with a hackable baseline for this competition.\n",
    "\n",
    "The unofficial secondary purpose (shhh!) is to get a shiny Kaggle medal. If you find it useful vote!\n",
    "\n",
    "\n",
    "## Introduction\n",
    "So far all kernels I see are not doing feature engineering in a maintainable and scalable way:\n",
    "* Feature engineering has to be done twice, once for training, one for testing.\n",
    "* It's contamination prone for cross-validation and GridSearch. (E.G. You compute the mean of the whole dataset and use it as a feature even though you cross-validate on 80% only for example).\n",
    "* Feature testing and scaling is all over the code.\n",
    "* You have to leave Pandas at one point and use NumPy array, meaning you lose context and label of data.\n",
    "* You can't find useful features in an easy automated way, especially after OneHotEncoding or LabelBinarizer.\n",
    "\n",
    "## Learning outcomes\n",
    "You will learn:\n",
    "* How to scale feature engineering with a Pipeline\n",
    "* How to debug easily any step in your feature engineering Pipeline\n",
    "* How to structure your code to enable/disable features in a single place (aka Command Center) and preprocess them properly (StandardScaler, LabelBinarizer, OneHotEncoder ...)\n",
    "* How to extract the most useful features from a feature set, even after OneHotEncoding or Binarization\n",
    "\n",
    "**The end goal is to have a very clean code that allows to test features very rapidly**\n",
    "\n",
    "What you will not learn:\n",
    "* Data exploration and visualization\n",
    "* Stacking in 2 liners, use mlxtend for that: https://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier/\n",
    "* Imputing missing values with advanced techniques (beyond mean/median/mode): check my Titanic kernels in [Python](https://www.kaggle.com/mratsim/titanic/titanic-end-to-end-pipeline-stacking-gridsearch) and [Julia](https://www.kaggle.com/mratsim/titanic/titanic-julia-end-to-end-pipelining) for examples.\n",
    "\n",
    "\n",
    "## Notes\n",
    "This is a port of [Li Li's kernel](https://www.kaggle.com/aikinogard/two-sigma-connect-rental-listing-inquiries/random-forest-starter-with-numerical-features) to Scikit's Pipeline. Thank you Li Li for some clean and to the point code.\n",
    "\n",
    "Unfortunately this kernel does not run completely at Kaggle kernel due to the lack of sklearn-pandas library that allows to use Pandas' dataframes with ScikitLearn\n",
    "\n",
    "The Baseline score is : 0.63"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries\n",
    "* Numerical libraries\n",
    "* ScikitLearn Tools\n",
    "* Classifier: XGBoost, using the Scikit Learn API\n",
    "* time: to name the output files\n",
    "\n",
    "sklearn-pandas is imported at a later time as it won't run in Kaggle anyway\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T10:33:13.886647",
     "start_time": "2017-02-18T10:33:13.697758"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T10:33:14.039891",
     "start_time": "2017-02-18T10:33:13.887577"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer, RobustScaler, Binarizer, StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T10:33:14.044947",
     "start_time": "2017-02-18T10:33:14.040866"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Impact sklearn_pandas which Pandas DataFrame compatibility with Scikit's classifiers and Pipeline\n",
    "from sklearn_pandas import DataFrameMapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T10:33:14.052860",
     "start_time": "2017-02-18T10:33:14.046097"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T10:33:14.055955",
     "start_time": "2017-02-18T10:33:14.054165"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and display data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T10:33:14.944263",
     "start_time": "2017-02-18T10:33:14.056778"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>building_id</th>\n",
       "      <th>created</th>\n",
       "      <th>description</th>\n",
       "      <th>display_address</th>\n",
       "      <th>features</th>\n",
       "      <th>interest_level</th>\n",
       "      <th>latitude</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>longitude</th>\n",
       "      <th>manager_id</th>\n",
       "      <th>photos</th>\n",
       "      <th>price</th>\n",
       "      <th>street_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>53a5b119ba8f7b61d4e010512e0dfc85</td>\n",
       "      <td>2016-06-24 07:54:24</td>\n",
       "      <td>A Brand New 3 Bedroom 1.5 bath ApartmentEnjoy ...</td>\n",
       "      <td>Metropolitan Avenue</td>\n",
       "      <td>[]</td>\n",
       "      <td>medium</td>\n",
       "      <td>40.7145</td>\n",
       "      <td>7211212</td>\n",
       "      <td>-73.9425</td>\n",
       "      <td>5ba989232d0489da1b5f2c45f6688adc</td>\n",
       "      <td>[https://photos.renthop.com/2/7211212_1ed4542e...</td>\n",
       "      <td>3000</td>\n",
       "      <td>792 Metropolitan Avenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>c5c8a357cba207596b04d1afd1e4f130</td>\n",
       "      <td>2016-06-12 12:19:27</td>\n",
       "      <td></td>\n",
       "      <td>Columbus Avenue</td>\n",
       "      <td>[Doorman, Elevator, Fitness Center, Cats Allow...</td>\n",
       "      <td>low</td>\n",
       "      <td>40.7947</td>\n",
       "      <td>7150865</td>\n",
       "      <td>-73.9667</td>\n",
       "      <td>7533621a882f71e25173b27e3139d83d</td>\n",
       "      <td>[https://photos.renthop.com/2/7150865_be3306c5...</td>\n",
       "      <td>5465</td>\n",
       "      <td>808 Columbus Avenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100004</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>c3ba40552e2120b0acfc3cb5730bb2aa</td>\n",
       "      <td>2016-04-17 03:26:41</td>\n",
       "      <td>Top Top West Village location, beautiful Pre-w...</td>\n",
       "      <td>W 13 Street</td>\n",
       "      <td>[Laundry In Building, Dishwasher, Hardwood Flo...</td>\n",
       "      <td>high</td>\n",
       "      <td>40.7388</td>\n",
       "      <td>6887163</td>\n",
       "      <td>-74.0018</td>\n",
       "      <td>d9039c43983f6e564b1482b273bd7b01</td>\n",
       "      <td>[https://photos.renthop.com/2/6887163_de85c427...</td>\n",
       "      <td>2850</td>\n",
       "      <td>241 W 13 Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100007</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>28d9ad350afeaab8027513a3e52ac8d5</td>\n",
       "      <td>2016-04-18 02:22:02</td>\n",
       "      <td>Building Amenities - Garage - Garden - fitness...</td>\n",
       "      <td>East 49th Street</td>\n",
       "      <td>[Hardwood Floors, No Fee]</td>\n",
       "      <td>low</td>\n",
       "      <td>40.7539</td>\n",
       "      <td>6888711</td>\n",
       "      <td>-73.9677</td>\n",
       "      <td>1067e078446a7897d2da493d2f741316</td>\n",
       "      <td>[https://photos.renthop.com/2/6888711_6e660cee...</td>\n",
       "      <td>3275</td>\n",
       "      <td>333 East 49th Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100013</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-28 01:32:41</td>\n",
       "      <td>Beautifully renovated 3 bedroom flex 4 bedroom...</td>\n",
       "      <td>West 143rd Street</td>\n",
       "      <td>[Pre-War]</td>\n",
       "      <td>low</td>\n",
       "      <td>40.8241</td>\n",
       "      <td>6934781</td>\n",
       "      <td>-73.9493</td>\n",
       "      <td>98e13ad4b495b9613cef886d79a6291f</td>\n",
       "      <td>[https://photos.renthop.com/2/6934781_1fa4b41a...</td>\n",
       "      <td>3350</td>\n",
       "      <td>500 West 143rd Street</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bathrooms  bedrooms                       building_id  \\\n",
       "10            1.5         3  53a5b119ba8f7b61d4e010512e0dfc85   \n",
       "10000         1.0         2  c5c8a357cba207596b04d1afd1e4f130   \n",
       "100004        1.0         1  c3ba40552e2120b0acfc3cb5730bb2aa   \n",
       "100007        1.0         1  28d9ad350afeaab8027513a3e52ac8d5   \n",
       "100013        1.0         4                                 0   \n",
       "\n",
       "                    created  \\\n",
       "10      2016-06-24 07:54:24   \n",
       "10000   2016-06-12 12:19:27   \n",
       "100004  2016-04-17 03:26:41   \n",
       "100007  2016-04-18 02:22:02   \n",
       "100013  2016-04-28 01:32:41   \n",
       "\n",
       "                                              description  \\\n",
       "10      A Brand New 3 Bedroom 1.5 bath ApartmentEnjoy ...   \n",
       "10000                                                       \n",
       "100004  Top Top West Village location, beautiful Pre-w...   \n",
       "100007  Building Amenities - Garage - Garden - fitness...   \n",
       "100013  Beautifully renovated 3 bedroom flex 4 bedroom...   \n",
       "\n",
       "            display_address  \\\n",
       "10      Metropolitan Avenue   \n",
       "10000       Columbus Avenue   \n",
       "100004          W 13 Street   \n",
       "100007     East 49th Street   \n",
       "100013    West 143rd Street   \n",
       "\n",
       "                                                 features interest_level  \\\n",
       "10                                                     []         medium   \n",
       "10000   [Doorman, Elevator, Fitness Center, Cats Allow...            low   \n",
       "100004  [Laundry In Building, Dishwasher, Hardwood Flo...           high   \n",
       "100007                          [Hardwood Floors, No Fee]            low   \n",
       "100013                                          [Pre-War]            low   \n",
       "\n",
       "        latitude  listing_id  longitude                        manager_id  \\\n",
       "10       40.7145     7211212   -73.9425  5ba989232d0489da1b5f2c45f6688adc   \n",
       "10000    40.7947     7150865   -73.9667  7533621a882f71e25173b27e3139d83d   \n",
       "100004   40.7388     6887163   -74.0018  d9039c43983f6e564b1482b273bd7b01   \n",
       "100007   40.7539     6888711   -73.9677  1067e078446a7897d2da493d2f741316   \n",
       "100013   40.8241     6934781   -73.9493  98e13ad4b495b9613cef886d79a6291f   \n",
       "\n",
       "                                                   photos  price  \\\n",
       "10      [https://photos.renthop.com/2/7211212_1ed4542e...   3000   \n",
       "10000   [https://photos.renthop.com/2/7150865_be3306c5...   5465   \n",
       "100004  [https://photos.renthop.com/2/6887163_de85c427...   2850   \n",
       "100007  [https://photos.renthop.com/2/6888711_6e660cee...   3275   \n",
       "100013  [https://photos.renthop.com/2/6934781_1fa4b41a...   3350   \n",
       "\n",
       "                 street_address  \n",
       "10      792 Metropolitan Avenue  \n",
       "10000       808 Columbus Avenue  \n",
       "100004          241 W 13 Street  \n",
       "100007     333 East 49th Street  \n",
       "100013    500 West 143rd Street  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_json(open(\"./data/train.json\", \"r\"))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T10:33:16.307424",
     "start_time": "2017-02-18T10:33:14.945288"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>building_id</th>\n",
       "      <th>created</th>\n",
       "      <th>description</th>\n",
       "      <th>display_address</th>\n",
       "      <th>features</th>\n",
       "      <th>latitude</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>longitude</th>\n",
       "      <th>manager_id</th>\n",
       "      <th>photos</th>\n",
       "      <th>price</th>\n",
       "      <th>street_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>79780be1514f645d7e6be99a3de696c5</td>\n",
       "      <td>2016-06-11 05:29:41</td>\n",
       "      <td>Large with awesome terrace--accessible via bed...</td>\n",
       "      <td>Suffolk Street</td>\n",
       "      <td>[Elevator, Laundry in Building, Laundry in Uni...</td>\n",
       "      <td>40.7185</td>\n",
       "      <td>7142618</td>\n",
       "      <td>-73.9865</td>\n",
       "      <td>b1b1852c416d78d7765d746cb1b8921f</td>\n",
       "      <td>[https://photos.renthop.com/2/7142618_1c45a2c8...</td>\n",
       "      <td>2950</td>\n",
       "      <td>99 Suffolk Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-06-24 06:36:34</td>\n",
       "      <td>Prime Soho - between Bleecker and Houston - Ne...</td>\n",
       "      <td>Thompson Street</td>\n",
       "      <td>[Pre-War, Dogs Allowed, Cats Allowed]</td>\n",
       "      <td>40.7278</td>\n",
       "      <td>7210040</td>\n",
       "      <td>-74.0000</td>\n",
       "      <td>d0b5648017832b2427eeb9956d966a14</td>\n",
       "      <td>[https://photos.renthop.com/2/7210040_d824cc71...</td>\n",
       "      <td>2850</td>\n",
       "      <td>176 Thompson Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3dbbb69fd52e0d25131aa1cd459c87eb</td>\n",
       "      <td>2016-06-03 04:29:40</td>\n",
       "      <td>New York chic has reached a new level ...</td>\n",
       "      <td>101 East 10th Street</td>\n",
       "      <td>[Doorman, Elevator, No Fee]</td>\n",
       "      <td>40.7306</td>\n",
       "      <td>7103890</td>\n",
       "      <td>-73.9890</td>\n",
       "      <td>9ca6f3baa475c37a3b3521a394d65467</td>\n",
       "      <td>[https://photos.renthop.com/2/7103890_85b33077...</td>\n",
       "      <td>3758</td>\n",
       "      <td>101 East 10th Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>783d21d013a7e655bddc4ed0d461cc5e</td>\n",
       "      <td>2016-06-11 06:17:35</td>\n",
       "      <td>Step into this fantastic new Construction in t...</td>\n",
       "      <td>South Third Street\\r</td>\n",
       "      <td>[Roof Deck, Balcony, Elevator, Laundry in Buil...</td>\n",
       "      <td>40.7109</td>\n",
       "      <td>7143442</td>\n",
       "      <td>-73.9571</td>\n",
       "      <td>0b9d5db96db8472d7aeb67c67338c4d2</td>\n",
       "      <td>[https://photos.renthop.com/2/7143442_0879e9e0...</td>\n",
       "      <td>3300</td>\n",
       "      <td>251  South Third Street\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6134e7c4dd1a98d9aee36623c9872b49</td>\n",
       "      <td>2016-04-12 05:24:17</td>\n",
       "      <td>~Take a stroll in Central Park, enjoy the ente...</td>\n",
       "      <td>Midtown West, 8th Ave</td>\n",
       "      <td>[Common Outdoor Space, Cats Allowed, Dogs Allo...</td>\n",
       "      <td>40.7650</td>\n",
       "      <td>6860601</td>\n",
       "      <td>-73.9845</td>\n",
       "      <td>b5eda0eb31b042ce2124fd9e9fcfce2f</td>\n",
       "      <td>[https://photos.renthop.com/2/6860601_c96164d8...</td>\n",
       "      <td>4900</td>\n",
       "      <td>260 West 54th Street</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bathrooms  bedrooms                       building_id  \\\n",
       "0             1.0         1  79780be1514f645d7e6be99a3de696c5   \n",
       "1             1.0         2                                 0   \n",
       "100           1.0         1  3dbbb69fd52e0d25131aa1cd459c87eb   \n",
       "1000          1.0         2  783d21d013a7e655bddc4ed0d461cc5e   \n",
       "100000        2.0         2  6134e7c4dd1a98d9aee36623c9872b49   \n",
       "\n",
       "                    created  \\\n",
       "0       2016-06-11 05:29:41   \n",
       "1       2016-06-24 06:36:34   \n",
       "100     2016-06-03 04:29:40   \n",
       "1000    2016-06-11 06:17:35   \n",
       "100000  2016-04-12 05:24:17   \n",
       "\n",
       "                                              description  \\\n",
       "0       Large with awesome terrace--accessible via bed...   \n",
       "1       Prime Soho - between Bleecker and Houston - Ne...   \n",
       "100             New York chic has reached a new level ...   \n",
       "1000    Step into this fantastic new Construction in t...   \n",
       "100000  ~Take a stroll in Central Park, enjoy the ente...   \n",
       "\n",
       "              display_address  \\\n",
       "0              Suffolk Street   \n",
       "1             Thompson Street   \n",
       "100      101 East 10th Street   \n",
       "1000     South Third Street\\r   \n",
       "100000  Midtown West, 8th Ave   \n",
       "\n",
       "                                                 features  latitude  \\\n",
       "0       [Elevator, Laundry in Building, Laundry in Uni...   40.7185   \n",
       "1                   [Pre-War, Dogs Allowed, Cats Allowed]   40.7278   \n",
       "100                           [Doorman, Elevator, No Fee]   40.7306   \n",
       "1000    [Roof Deck, Balcony, Elevator, Laundry in Buil...   40.7109   \n",
       "100000  [Common Outdoor Space, Cats Allowed, Dogs Allo...   40.7650   \n",
       "\n",
       "        listing_id  longitude                        manager_id  \\\n",
       "0          7142618   -73.9865  b1b1852c416d78d7765d746cb1b8921f   \n",
       "1          7210040   -74.0000  d0b5648017832b2427eeb9956d966a14   \n",
       "100        7103890   -73.9890  9ca6f3baa475c37a3b3521a394d65467   \n",
       "1000       7143442   -73.9571  0b9d5db96db8472d7aeb67c67338c4d2   \n",
       "100000     6860601   -73.9845  b5eda0eb31b042ce2124fd9e9fcfce2f   \n",
       "\n",
       "                                                   photos  price  \\\n",
       "0       [https://photos.renthop.com/2/7142618_1c45a2c8...   2950   \n",
       "1       [https://photos.renthop.com/2/7210040_d824cc71...   2850   \n",
       "100     [https://photos.renthop.com/2/7103890_85b33077...   3758   \n",
       "1000    [https://photos.renthop.com/2/7143442_0879e9e0...   3300   \n",
       "100000  [https://photos.renthop.com/2/6860601_c96164d8...   4900   \n",
       "\n",
       "                   street_address  \n",
       "0               99 Suffolk Street  \n",
       "1             176 Thompson Street  \n",
       "100          101 East 10th Street  \n",
       "1000    251  South Third Street\\r  \n",
       "100000       260 West 54th Street  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_json(open(\"./data/test.json\", \"r\"))\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers\n",
    "\n",
    "This is the main lesson of this code. Transformers allow your code to be easily maintainable by wrapping eachpreprocessing step in an easily testable class :\n",
    "* You will always be sure that transformations are applied to train and test data\n",
    "* You won't have to track matrix sizes, column names\n",
    "* You can store temporary data in the training phase to reuse in the testing phase in a clean way, for example the number of occurences of a manager id.\n",
    "\n",
    "Transformers have 4 methods:\n",
    "\n",
    "**\\_\\_init\\_\\_**\n",
    "\n",
    "Usually at \"pass\", it's useful:\n",
    "* for temporary variables, like a dictionary to do some mapping\n",
    "* if you need to store data from the training phase to reuse during the predict phase. Check my [Titanic Kernel](https://www.kaggle.com/mratsim/titanic/titanic-end-to-end-pipeline-stacking-gridsearch)\n",
    "\n",
    "**fit**\n",
    "\n",
    "If the transformer don't learn from the input data (same transformation at training and testing phase) it should return self\n",
    "If the transformer \"learns\" from the data, i.e. tehre is one or more internal properties in the __init__ methods, update the properties and then return self. Those properties can then be used in the transform method\n",
    "\n",
    "**transform**\n",
    "\n",
    "How the transformer transform the data\n",
    "\n",
    "**predict**\n",
    "\n",
    "This is used if you build [your custom classifier](http://scikit-learn.org/dev/developers/contributing.html#rolling-your-own-estimator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T10:33:16.327764",
     "start_time": "2017-02-18T10:33:16.308248"
    },
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This transformer extracts the number of photos\n",
    "def transformer_numphot(train, test):\n",
    "    def _trans(df):\n",
    "        return df.assign(NumPhotos = df['photos'].str.len())\n",
    "    return _trans(train), _trans(test)\n",
    "    \n",
    "# This transformer extracts the number of features\n",
    "def transformer_numfeat(train, test):\n",
    "    def _trans(df):\n",
    "        return df.assign(NumFeat = df['features'].str.len())\n",
    "    return _trans(train), _trans(test)\n",
    "    \n",
    "# This transformer extracts the number of words in the description\n",
    "def transformer_numdescwords(train, test):\n",
    "    def _trans(df):\n",
    "        return df.assign(\n",
    "            NumDescWords = df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "            )\n",
    "    return _trans(train), _trans(test)\n",
    "    \n",
    "# This transformer extracts the date/month/year and timestamp in a neat package\n",
    "def transformer_datetime(train,test):\n",
    "    def _trans(df):\n",
    "        df = df.assign(\n",
    "            Created_TS = pd.to_datetime(df[\"created\"])\n",
    "        )\n",
    "        return df.assign(\n",
    "            Created_Year = df[\"Created_TS\"].dt.year,\n",
    "            Created_Month = df[\"Created_TS\"].dt.month,\n",
    "            Created_Day = df[\"Created_TS\"].dt.day\n",
    "            )\n",
    "    return _trans(train), _trans(test)\n",
    "\n",
    "# Bucket nombre de chambres et de bathrooms\n",
    "# Heure de la journée\n",
    "# Jour de la semaine\n",
    "# Retirer numéro de rue\n",
    "# Imputer les rues sans géoloc\n",
    "# Quartier (centre le plus proche)\n",
    "# Distance par rapport au centre\n",
    "# Clusteriser la latitude/longitude\n",
    "# Features: categorizer\n",
    "# manager skill (2*high + medium)\n",
    "\n",
    "####### Debug Transformer ###########\n",
    "# Use this transformer anywhere in your Pipeline to dump your dataframe to CSV\n",
    "def transformer_debug(train,test):\n",
    "    X.to_csv('./debug_train.csv')\n",
    "    y.to_csv('./debug_test.csv')\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions for functional programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T10:33:16.335469",
     "start_time": "2017-02-18T10:33:16.328676"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# inspired by: https://joshbohde.com/blog/functional-python\n",
    "# Transformations do not take extra arguments so no need for partial or starmap\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "#compose list of functions (chained composition)\n",
    "def compose(*funcs):\n",
    "    def _compose(f, g):\n",
    "        # functions are expecting X,y not (X,y) so must unpack with *g\n",
    "        return lambda *args, **kwargs: f(*g(*args, **kwargs))\n",
    "    return reduce(_compose, funcs)\n",
    "\n",
    "# pipe function, reverse the order so that it's usual FIFO function order\n",
    "def pipe(*funcs):\n",
    "    return compose(*reversed(funcs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Command Center - enabled features\n",
    "\n",
    "This is where you:\n",
    "* enable/disable features\n",
    "* specify scaling, onehotencoding, labelbinarizing\n",
    "\n",
    "\n",
    "Note: LabelBinarizer use the following syntax (\"feature\", LabelBinarizer())\n",
    "instead of ([\"feature\"], LabelBinarizer())\n",
    "\n",
    "Note2: Copy Pasting your DataFrameMapper config when you submit your results makes for a superb description of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T10:33:16.342329",
     "start_time": "2017-02-18T10:33:16.336319"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mapper = DataFrameMapper([\n",
    "    ([\"bathrooms\"],RobustScaler()), #Some bathrooms number are 1.5, Some outliers are 112 or 20    ([\"bedrooms\"],OneHotEncoder()),\n",
    "    ([\"latitude\"],None),\n",
    "    ([\"longitude\"],None),\n",
    "    ([\"price\"],RobustScaler()),\n",
    "    # ([\"NumDescWords\"],None),\n",
    "    ([\"NumFeat\"],StandardScaler()),\n",
    "    ([\"Created_Year\"],None),\n",
    "    ([\"Created_Month\"],None),\n",
    "    ([\"Created_Day\"],None)\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Command Center - feature engineering pipeline + classifier\n",
    "\n",
    "This is your transformation pipeline in the format:\n",
    "(\"arbitrary_name\", Transformer())\n",
    "\n",
    "You can comment/uncomment to remove/add steps.\n",
    "The last step should be your classifier.\n",
    "\n",
    "Note: if you need to configure a specific step \"step\" use the format step\\_\\_parameter = value\n",
    "\n",
    "For example I wanted to set the eval_metric of xgboost (name xgb) during the fit step so I used:\n",
    "\n",
    "pipe.fit(X_train, y_train, **xgb\\__eval_metric**='mlogloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T10:33:16.347127",
     "start_time": "2017-02-18T10:33:16.343162"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featurize = pipe(\n",
    "    transformer_numphot,\n",
    "    transformer_numfeat,\n",
    "    transformer_numdescwords,\n",
    "    transformer_datetime\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions\n",
    "\n",
    "## Cross Validation\n",
    "5 folds, results summarized with 3 decimals of precision\n",
    "\n",
    "## Get features that contributes most to the score\n",
    "This function gives sensible names in case of OneHotEncoding or LabelBinarizer.\n",
    "This is only possible with classifiers that implements **feature\\_importances_** like RandomForest, ExtraTrees or XGBoost.\n",
    "\n",
    "It outputs a top_featurs.csv files\n",
    "\n",
    "## Predict and format the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T10:33:16.357284",
     "start_time": "2017-02-18T10:33:16.347958"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Cross Validation #######\n",
    "def crossval(X,y,n):\n",
    "    cv = cross_val_score(pipe, X, y, cv=n)\n",
    "    print(\"Cross Validation Scores are: \", cv.round(3))\n",
    "    print(\"Mean CrossVal score is: \", round(cv.mean(),3))\n",
    "    print(\"Std Dev CrossVal score is: \", round(cv.std(),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T10:33:16.365776",
     "start_time": "2017-02-18T10:33:16.358436"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####### Get top features and noise #######\n",
    "def top_feat():\n",
    "    dummy, model = pipe.steps[-1]\n",
    "\n",
    "    feature_list = []\n",
    "    for feature in pipe.named_steps['featurize'].features:\n",
    "        if isinstance(feature[1], OneHotEncoder):\n",
    "            for feature_value in feature[1].active_features_:\n",
    "                feature_list.append(feature[0][0]+'_'+str(feature_value))\n",
    "        else:\n",
    "            try:\n",
    "                for feature_value in feature[1].classes_:\n",
    "                    feature_list.append(feature[0]+'_'+feature_value)\n",
    "            except:\n",
    "                feature_list.append(feature[0])\n",
    "\n",
    "\n",
    "    top_features = pd.DataFrame({'feature':feature_list,'importance':np.round(model.feature_importances_,3)})\n",
    "    top_features = top_features.sort_values('importance',ascending=False).set_index('feature')\n",
    "    top_features.to_csv('./top_features.csv')\n",
    "    top_features.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T10:33:16.371974",
     "start_time": "2017-02-18T10:33:16.366697"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "####### Predict and format output #######\n",
    "def output():\n",
    "    predictions = pipe.predict_proba(df_test,\n",
    "                                     lgbm__num_iteration=pipe.named_steps['lgbm'].best_iteration)\n",
    "    \n",
    "    #debug\n",
    "    print(pipe.classes_)\n",
    "    print(predictions)\n",
    "    \n",
    "    result = pd.DataFrame({\n",
    "        'listing_id': df_test['listing_id'],\n",
    "        pipe.classes_[0]: [row[0] for row in predictions], \n",
    "        pipe.classes_[1]: [row[1] for row in predictions],\n",
    "        pipe.classes_[2]: [row[2] for row in predictions]\n",
    "        })\n",
    "    result.to_csv(time.strftime(\"%Y-%m-%d_%H%M-\")+'-002-feat-eng.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T10:33:17.128425",
     "start_time": "2017-02-18T10:33:16.372966"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################ Model Selection ################################\n",
    "df_train, df_test = featurize(df_train,df_test)\n",
    "\n",
    "\n",
    "X = df_train\n",
    "y = df_train['interest_level']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T10:33:17.151171",
     "start_time": "2017-02-18T10:33:17.129689"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10        medium\n",
       "10000        low\n",
       "100004      high\n",
       "100007       low\n",
       "100013       low\n",
       "100014    medium\n",
       "100016       low\n",
       "100020       low\n",
       "100026    medium\n",
       "100027       low\n",
       "100030       low\n",
       "10004        low\n",
       "100044      high\n",
       "100048       low\n",
       "10005        low\n",
       "100051    medium\n",
       "100052       low\n",
       "100053       low\n",
       "100055       low\n",
       "100058       low\n",
       "100062       low\n",
       "100063    medium\n",
       "100065       low\n",
       "100066       low\n",
       "10007     medium\n",
       "100071       low\n",
       "100075    medium\n",
       "100076       low\n",
       "100079      high\n",
       "100081       low\n",
       "           ...  \n",
       "99915        low\n",
       "99917        low\n",
       "99919     medium\n",
       "99921     medium\n",
       "99923        low\n",
       "99924        low\n",
       "99931        low\n",
       "99933        low\n",
       "99935        low\n",
       "99937        low\n",
       "9994         low\n",
       "99953        low\n",
       "99956        low\n",
       "99960     medium\n",
       "99961        low\n",
       "99964     medium\n",
       "99965        low\n",
       "99966        low\n",
       "99979        low\n",
       "99980        low\n",
       "99982       high\n",
       "99984        low\n",
       "99986        low\n",
       "99987        low\n",
       "99988     medium\n",
       "9999      medium\n",
       "99991        low\n",
       "99992        low\n",
       "99993        low\n",
       "99994        low\n",
       "Name: interest_level, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T10:33:17.208488",
     "start_time": "2017-02-18T10:33:17.152469"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T10:33:17.214724",
     "start_time": "2017-02-18T10:33:17.209868"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59100        low\n",
       "108970       low\n",
       "102253      high\n",
       "77900        low\n",
       "17279        low\n",
       "19745        low\n",
       "60258        low\n",
       "88633     medium\n",
       "98546        low\n",
       "30563        low\n",
       "72559        low\n",
       "43996        low\n",
       "70034        low\n",
       "12875     medium\n",
       "64731        low\n",
       "98805       high\n",
       "88366        low\n",
       "57920     medium\n",
       "68970        low\n",
       "60395        low\n",
       "21395        low\n",
       "4796      medium\n",
       "22938        low\n",
       "17905        low\n",
       "77099     medium\n",
       "107451       low\n",
       "27354     medium\n",
       "46827        low\n",
       "2870      medium\n",
       "66860        low\n",
       "           ...  \n",
       "101350       low\n",
       "22319        low\n",
       "50130        low\n",
       "21203        low\n",
       "81583        low\n",
       "4607         low\n",
       "93516        low\n",
       "60813        low\n",
       "71894     medium\n",
       "66622        low\n",
       "45875        low\n",
       "100854       low\n",
       "30892        low\n",
       "123373      high\n",
       "18773        low\n",
       "15843     medium\n",
       "96283        low\n",
       "16692     medium\n",
       "9606      medium\n",
       "82926     medium\n",
       "101051    medium\n",
       "70516        low\n",
       "67922     medium\n",
       "61286       high\n",
       "103270       low\n",
       "122671       low\n",
       "115295       low\n",
       "18048        low\n",
       "66805        low\n",
       "83451        low\n",
       "Name: interest_level, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T10:33:17.242714",
     "start_time": "2017-02-18T10:33:17.216005"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train = mapper.fit_transform(X_train)\n",
    "\n",
    "X_test = mapper.transform(X_test)\n",
    "\n",
    "df_test = mapper.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T10:34:47.087257",
     "start_time": "2017-02-18T10:34:47.085090"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = y_train.as_matrix()\n",
    "y_test = y_test.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T10:33:36.559930",
     "start_time": "2017-02-18T10:33:36.554520"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Metric Multiclass log loss\n",
    "def multiclass_log_loss(y_true, y_pred, eps=1e-15):\n",
    "    \"\"\"Multi class version of Logarithmic Loss metric.\n",
    "    https://www.kaggle.com/wiki/MultiClassLogLoss\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array, shape = [n_samples]\n",
    "            true class, intergers in [0, n_classes - 1)\n",
    "    y_pred : array, shape = [n_samples, n_classes]\n",
    "    Returns\n",
    "    -------\n",
    "    loss : float\n",
    "    \"\"\"\n",
    "    predictions = np.clip(y_pred, eps, 1 - eps)\n",
    "\n",
    "    # normalize row sums to 1\n",
    "    predictions /= predictions.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    actual = np.zeros(y_pred.shape)\n",
    "    n_samples = actual.shape[0]\n",
    "    actual[np.arange(n_samples), y_true.astype(int)] = 1\n",
    "    vectsum = np.sum(actual * np.log(predictions))\n",
    "    loss = -1.0 / n_samples * vectsum\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T10:34:54.841016",
     "start_time": "2017-02-18T10:34:54.838757"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T10:34:57.094497",
     "start_time": "2017-02-18T10:34:57.091672"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['low', 'low', 'low', ..., 'low', 'medium', 'low'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T10:35:02.389437",
     "start_time": "2017-02-18T10:35:02.347972"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'low'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-811064b9c1dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                categorical_feature='auto')\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, callbacks)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;34m\"\"\"construct booster\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0mbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, train_set, model_file, silent)\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0;34m\"\"\"construct booster object\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             _safe_call(_LIB.LGBM_BoosterCreate(\n\u001b[0;32m-> 1189\u001b[0;31m                 \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 ctypes.byref(self.handle)))\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    785\u001b[0m                                 \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predictor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m                                 \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                                 categorical_feature=self.categorical_feature, params=self.params)\n\u001b[0m\u001b[1;32m    788\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree_raw_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m(self, data, label, max_bin, reference, weight, group, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[1;32m    658\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot initialize Dataset from {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Label should not be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mset_label\u001b[0;34m(self, label)\u001b[0m\n\u001b[1;32m   1021\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist_to_1d_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_field\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mlist_to_1d_numpy\u001b[0;34m(data, dtype, name)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_1d_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'low'"
     ]
    }
   ],
   "source": [
    "# specify your configurations as a dict\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 3,\n",
    "    'metric': {'multi_logloss'},\n",
    "    'learning_rate': 0.1,\n",
    "    #'feature_fraction': 0.9,\n",
    "    #'bagging_fraction': 0.8,\n",
    "    #'bagging_freq': 5,\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "print('Start training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=999,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=50,\n",
    "               feature_name='auto',\n",
    "               categorical_feature='auto')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T09:49:45.093818",
     "start_time": "2017-02-18T09:49:45.091190"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Start predicting...')\n",
    "# predict\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "# eval\n",
    "print('The mlogloss of prediction is:', multiclass_log_loss(t, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T09:47:07.066124",
     "start_time": "2017-02-18T09:47:06.304Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = pd.get_dummies(y_test).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T09:47:07.066268",
     "start_time": "2017-02-18T09:47:06.306Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred.save('dump.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-17T23:43:20.805415",
     "start_time": "2017-02-17T23:43:20.782786"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm.predict(df_test, num_iteration=gbm.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test = featurize(X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-17T22:17:07.654871",
     "start_time": "2017-02-17T22:17:07.645706"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "################ Cross Validation ################################\n",
    "crossval(X,y,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-17T01:36:35.856913",
     "start_time": "2017-02-17T01:30:49.217Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### Most influential features ########\n",
    "top_feat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-17T01:36:35.857071",
     "start_time": "2017-02-17T01:30:49.219Z"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######## Predict ########\n",
    "output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The End\n",
    "\n",
    "I hope you enjoyed the kernel and that it will help you iterate and test faster in your feature engineering quest.\n",
    "\n",
    "Thank you for your attention, feel free to post comment and upvote.\n",
    "\n",
    "You can check advanced transformer usage on my Titanic kernels in [Python](https://www.kaggle.com/mratsim/titanic/titanic-end-to-end-pipeline-stacking-gridsearch) and [Julia](https://www.kaggle.com/mratsim/titanic/titanic-julia-end-to-end-pipelining)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
